{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eng_Hin_NMT_custom",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1j0cpqfmp6bues9L_wFXCNLQu36pjd91S",
      "authorship_tag": "ABX9TyNNo4grpyOJcvcklgQU3Lk0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohan-vr/Natural-Language-Processing/blob/master/Eng_Hin_NMT_custom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL-umFOCbvNZ",
        "colab_type": "text"
      },
      "source": [
        "Import all the necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqzKHmkW9-vx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pickle import load\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Activation, Dropout\n",
        "from keras.layers import Dense, Bidirectional\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.optimizers import RMSprop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoAZ2WQ4cmgb",
        "colab_type": "text"
      },
      "source": [
        "Now comes the part of loading our cleaned English and Hindi datasets and create tokenizer for English dataset and Hindi dataset and then we find the max length of sentences of English and Hindi. At last we encode sequences to prepare training data and validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3FJApFMcv2T",
        "colab_type": "code",
        "outputId": "f3c8e540-4b46-4ede-f51b-73a3bd3c30bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# load a clean dataset\n",
        "def load_clean_sentences(filename):\n",
        "\treturn load(open(filename, 'rb'))\n",
        "\n",
        "# fit a tokenizer\n",
        "def create_tokenizer(lines):\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer\n",
        "\n",
        "# max sentence length\n",
        "def max_length(lines):\n",
        "\treturn max(len(line.split()) for line in lines)\n",
        "\n",
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "\t# integer encode sequences\n",
        "\tX = tokenizer.texts_to_sequences(lines)\n",
        "\t# pad sequences with 0 values\n",
        "\tX = pad_sequences(X, maxlen=length, padding='post')\n",
        "\treturn X\n",
        "\n",
        "# load datasets\n",
        "dataset = load_clean_sentences('en-hi-both.pkl')\n",
        "train = load_clean_sentences('en-hi-train.pkl')\n",
        "test = load_clean_sentences('en-hi-test.pkl')\n",
        "\n",
        "# prepare english tokenizer\n",
        "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "eng_length = max_length(dataset[:, 0])\n",
        "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
        "print('English Max Length: %d' % (eng_length))\n",
        "\n",
        "# prepare german tokenizer\n",
        "hin_tokenizer = create_tokenizer(dataset[:, 1])\n",
        "hin_vocab_size = len(hin_tokenizer.word_index) + 1\n",
        "hin_length = max_length(dataset[:, 1])\n",
        "print('Hindi Vocabulary Size: %d' % hin_vocab_size)\n",
        "print('Hindi Max Length: %d' % (hin_length))\n",
        "\n",
        "# prepare training data\n",
        "trainX = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
        "trainY = encode_sequences(hin_tokenizer, hin_length, train[:, 1])\n",
        "\n",
        "# prepare validation data\n",
        "testX = encode_sequences(eng_tokenizer, eng_length, test[:, 0])\n",
        "testY = encode_sequences(hin_tokenizer, hin_length, test[:, 1])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocabulary Size: 36441\n",
            "English Max Length: 15\n",
            "Hindi Vocabulary Size: 49562\n",
            "Hindi Max Length: 17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_FcATkrenpU",
        "colab_type": "text"
      },
      "source": [
        "Now comes the part to define our model. Lets do it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmwfmLFMexnn",
        "colab_type": "code",
        "outputId": "36dad799-8265-4f6c-a173-46bd40a5eb1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "def define_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
        "\tmodel.add(Bidirectional(LSTM(units=n_units)))\n",
        "\tmodel.add(RepeatVector(tar_timesteps))\n",
        "\tmodel.add(LSTM(n_units, return_sequences=True))\n",
        "\tmodel.add(Dense(tar_vocab, activation='softmax'))\n",
        "\treturn model\n",
        "\n",
        "model = define_model(eng_vocab_size, hin_vocab_size, eng_length, hin_length, 512)\n",
        "rms = RMSprop(lr=0.001)\n",
        "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')\n",
        "print(model.summary())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 15, 512)           18657792  \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, 1024)              4198400   \n",
            "_________________________________________________________________\n",
            "repeat_vector_5 (RepeatVecto (None, 17, 1024)          0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 17, 512)           3147776   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 17, 49562)         25425306  \n",
            "=================================================================\n",
            "Total params: 51,429,274\n",
            "Trainable params: 51,429,274\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgEyt8XUfB4U",
        "colab_type": "text"
      },
      "source": [
        "Now let us save the model. Dont forget to save checkpoints."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN-Jc7KOfLB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = 'model.h1.24_april_20'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlmKN1Cvfi_Y",
        "colab_type": "text"
      },
      "source": [
        "Now let us train the model and keep a track of loss and validation loss which will help us to plot these two variables in a graph so we can visualize it easily."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-9slzDxfw67",
        "colab_type": "code",
        "outputId": "0b452e4f-e904-4358-8c1e-25e8db941fcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1), epochs=30, batch_size=512, validation_split=0.1, callbacks=[checkpoint],  verbose=1)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['train','validation'])\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 216000 samples, validate on 24000 samples\n",
            "Epoch 1/30\n",
            "216000/216000 [==============================] - 267s 1ms/step - loss: 2.4804 - val_loss: 2.1540\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.15399, saving model to model.h1.24_april_20\n",
            "Epoch 2/30\n",
            "216000/216000 [==============================] - 265s 1ms/step - loss: 2.0001 - val_loss: 1.8702\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.15399 to 1.87024, saving model to model.h1.24_april_20\n",
            "Epoch 3/30\n",
            "216000/216000 [==============================] - 264s 1ms/step - loss: 1.7322 - val_loss: 1.6587\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.87024 to 1.65871, saving model to model.h1.24_april_20\n",
            "Epoch 4/30\n",
            "216000/216000 [==============================] - 265s 1ms/step - loss: 1.5301 - val_loss: 1.5019\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.65871 to 1.50188, saving model to model.h1.24_april_20\n",
            "Epoch 5/30\n",
            "216000/216000 [==============================] - 265s 1ms/step - loss: 1.3713 - val_loss: 1.3912\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.50188 to 1.39125, saving model to model.h1.24_april_20\n",
            "Epoch 6/30\n",
            "216000/216000 [==============================] - 264s 1ms/step - loss: 1.2429 - val_loss: 1.2997\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.39125 to 1.29965, saving model to model.h1.24_april_20\n",
            "Epoch 7/30\n",
            "216000/216000 [==============================] - 263s 1ms/step - loss: 1.1369 - val_loss: 1.2326\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.29965 to 1.23264, saving model to model.h1.24_april_20\n",
            "Epoch 8/30\n",
            "216000/216000 [==============================] - 263s 1ms/step - loss: 1.0509 - val_loss: 1.1904\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.23264 to 1.19039, saving model to model.h1.24_april_20\n",
            "Epoch 9/30\n",
            "216000/216000 [==============================] - 263s 1ms/step - loss: 0.9782 - val_loss: 1.1434\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.19039 to 1.14339, saving model to model.h1.24_april_20\n",
            "Epoch 10/30\n",
            "216000/216000 [==============================] - 264s 1ms/step - loss: 0.9148 - val_loss: 1.1100\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.14339 to 1.10997, saving model to model.h1.24_april_20\n",
            "Epoch 11/30\n",
            "216000/216000 [==============================] - 262s 1ms/step - loss: 0.8616 - val_loss: 1.0906\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.10997 to 1.09055, saving model to model.h1.24_april_20\n",
            "Epoch 12/30\n",
            "216000/216000 [==============================] - 264s 1ms/step - loss: 0.8144 - val_loss: 1.0715\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.09055 to 1.07152, saving model to model.h1.24_april_20\n",
            "Epoch 13/30\n",
            "216000/216000 [==============================] - 263s 1ms/step - loss: 0.7728 - val_loss: 1.0634\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.07152 to 1.06344, saving model to model.h1.24_april_20\n",
            "Epoch 14/30\n",
            "216000/216000 [==============================] - 266s 1ms/step - loss: 0.7361 - val_loss: 1.0518\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.06344 to 1.05184, saving model to model.h1.24_april_20\n",
            "Epoch 15/30\n",
            "216000/216000 [==============================] - 265s 1ms/step - loss: 0.7023 - val_loss: 1.0513\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.05184 to 1.05130, saving model to model.h1.24_april_20\n",
            "Epoch 16/30\n",
            "216000/216000 [==============================] - 265s 1ms/step - loss: 0.6725 - val_loss: 1.0474\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.05130 to 1.04737, saving model to model.h1.24_april_20\n",
            "Epoch 17/30\n",
            "216000/216000 [==============================] - 264s 1ms/step - loss: 0.6448 - val_loss: 1.0430\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.04737 to 1.04303, saving model to model.h1.24_april_20\n",
            "Epoch 18/30\n",
            "216000/216000 [==============================] - 264s 1ms/step - loss: 0.6191 - val_loss: 1.0449\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.04303\n",
            "Epoch 19/30\n",
            "216000/216000 [==============================] - 263s 1ms/step - loss: 0.5964 - val_loss: 1.0482\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.04303\n",
            "Epoch 20/30\n",
            "216000/216000 [==============================] - 263s 1ms/step - loss: 0.5746 - val_loss: 1.0542\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.04303\n",
            "Epoch 21/30\n",
            "216000/216000 [==============================] - 262s 1ms/step - loss: 0.5545 - val_loss: 1.0568\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.04303\n",
            "Epoch 22/30\n",
            "216000/216000 [==============================] - 263s 1ms/step - loss: 0.5350 - val_loss: 1.0594\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.04303\n",
            "Epoch 23/30\n",
            "216000/216000 [==============================] - 262s 1ms/step - loss: 0.5163 - val_loss: 1.0633\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.04303\n",
            "Epoch 24/30\n",
            "216000/216000 [==============================] - 262s 1ms/step - loss: 0.4998 - val_loss: 1.0697\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.04303\n",
            "Epoch 25/30\n",
            "216000/216000 [==============================] - 262s 1ms/step - loss: 0.4850 - val_loss: 1.0756\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.04303\n",
            "Epoch 26/30\n",
            "216000/216000 [==============================] - 261s 1ms/step - loss: 0.4700 - val_loss: 1.0784\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.04303\n",
            "Epoch 27/30\n",
            "216000/216000 [==============================] - 263s 1ms/step - loss: 0.4561 - val_loss: 1.0874\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.04303\n",
            "Epoch 28/30\n",
            "216000/216000 [==============================] - 262s 1ms/step - loss: 0.4432 - val_loss: 1.0884\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.04303\n",
            "Epoch 29/30\n",
            "216000/216000 [==============================] - 261s 1ms/step - loss: 0.4308 - val_loss: 1.0946\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.04303\n",
            "Epoch 30/30\n",
            "216000/216000 [==============================] - 263s 1ms/step - loss: 0.4192 - val_loss: 1.0990\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.04303\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqB0VGVaf-en",
        "colab_type": "text"
      },
      "source": [
        "Okay so now we are done with training. As we can see the graph, that is a pretty smooth curve! Now is the time to test our model. First we will load the model then make predictions over the test dataset we created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dpxYHbigGdu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "7f520320-e890-4d9f-db47-9539a7b62839"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "testX=testX[0:100] # lets take 50 sentences of test data set\n",
        "\n",
        "model = load_model('model.h1.24_april_20')\n",
        "\n",
        "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))\n",
        "\n",
        "# a function that is going to grab words.\n",
        "def get_word(n, tokenizer):\n",
        "      for word, index in tokenizer.word_index.items():\n",
        "          if index == n:\n",
        "              return word\n",
        "      return None\n",
        "\n",
        "preds_text = []\n",
        "for i in preds:\n",
        "       temp = []\n",
        "       for j in range(len(i)):\n",
        "            t = get_word(i[j], hin_tokenizer)\n",
        "            if j > 0:\n",
        "                if (t == get_word(i[j-1], hin_tokenizer)) or (t == None):\n",
        "                     temp.append('')\n",
        "                else:\n",
        "                     temp.append(t)\n",
        "            else:\n",
        "                   if(t == None):\n",
        "                          temp.append('')\n",
        "                   else:\n",
        "                          temp.append(t) \n",
        "\n",
        "       preds_text.append(' '.join(temp))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1joGDMwgY9P",
        "colab_type": "text"
      },
      "source": [
        "Okay so now time to visualize predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNCi_h-Ggd_N",
        "colab_type": "code",
        "outputId": "e1852da8-6e72-486a-c0e0-a1961d59239f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "import pandas as pd\n",
        "pred_df = pd.DataFrame({'input' : test[0:50,0], 'actual' : test[0:50,1], 'predicted' : preds_text})\n",
        "pred_df.sample(15)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>actual</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>custom location</td>\n",
              "      <td>पसंदीदा स्थानः</td>\n",
              "      <td>अनुकूलित स्थान</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>if it snows tomorrow i ll build a snowman</td>\n",
              "      <td>अगर कल बर्फ़ गिरी तो मैं स्नोमैन बनाऊंगा।</td>\n",
              "      <td>अगर कल   तो</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>close the current archive</td>\n",
              "      <td>वर्तमान अभिलेख बन्द करें</td>\n",
              "      <td>वर्तमान अभिलेख बन्द करें</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>paragraph background set</td>\n",
              "      <td>पैराग्राफ पृष्ठभूमि सेट</td>\n",
              "      <td>पृष्ठभूमि</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>select a disc to write to</td>\n",
              "      <td>डिस्क चुनें जिसमें लिखना है</td>\n",
              "      <td>डिस्क चुनें जिसमें लिखना है</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>krecipes exported recipes</td>\n",
              "      <td>केरेसिपि निर्यात किए गए रेसिपि</td>\n",
              "      <td>परवरदिगार निर्दिष्ट कॉन्फ़िगर</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>member</td>\n",
              "      <td>सदस्य</td>\n",
              "      <td>सदस्य</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>this which we recite unto thee is of the signs...</td>\n",
              "      <td>ये आयतें है और हिकमत तत्वज्ञान से परिपूर्ण अनु...</td>\n",
              "      <td>ये आयतें है और हिकमत तत्वज्ञान से परिपूर्ण अनु...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>choosing books help is at hand</td>\n",
              "      <td>किताबें चुननासहायता समीप ही उपलब्ध है।</td>\n",
              "      <td>यहां के    हैं</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>and restrain their carnal desires</td>\n",
              "      <td>और जो अपने गुप्तांगों की रक्षा करते है</td>\n",
              "      <td>और जो अपनी शर्मगाहों को हराम को बचाते</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>these are the oldest known books in the histor...</td>\n",
              "      <td>विश्व के वाङ्मय में इनसे प्राचीनतम कोई पुस्तक ...</td>\n",
              "      <td>ये दोनों इन धर्म   की में  से है।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>gambia</td>\n",
              "      <td>गामाः</td>\n",
              "      <td>अत्यन्त</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>passphrase dialog</td>\n",
              "      <td>पोर्ट</td>\n",
              "      <td>एक संवाद</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>connected to host</td>\n",
              "      <td>होस्ट 1 से जुड़ा है</td>\n",
              "      <td>होस्ट से कनेक्टेड</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>we command but once our will is done in the tw...</td>\n",
              "      <td>और हमारा हुक्म तो बस ऑंख के झपकने की तरह एक बा...</td>\n",
              "      <td>और हमने  एक  बस है वह  एक  भी है</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                input  ...                                          predicted\n",
              "46                                    custom location  ...                      अनुकूलित स्थान               \n",
              "7           if it snows tomorrow i ll build a snowman  ...                            अगर कल   तो            \n",
              "42                          close the current archive  ...              वर्तमान अभिलेख बन्द करें             \n",
              "25                           paragraph background set  ...                          पृष्ठभूमि                \n",
              "17                          select a disc to write to  ...            डिस्क चुनें जिसमें लिखना है            \n",
              "44                          krecipes exported recipes  ...        परवरदिगार निर्दिष्ट कॉन्फ़िगर              \n",
              "34                                             member  ...                              सदस्य                \n",
              "37  this which we recite unto thee is of the signs...  ...  ये आयतें है और हिकमत तत्वज्ञान से परिपूर्ण अनु...\n",
              "0                      choosing books help is at hand  ...                          यहां के    हैं           \n",
              "11                  and restrain their carnal desires  ...     और जो अपनी शर्मगाहों को हराम को बचाते         \n",
              "43  these are the oldest known books in the histor...  ...            ये दोनों इन धर्म   की में  से है।      \n",
              "38                                             gambia  ...                            अत्यन्त                \n",
              "14                                  passphrase dialog  ...                            एक संवाद               \n",
              "39                                  connected to host  ...                    होस्ट से कनेक्टेड              \n",
              "10  we command but once our will is done in the tw...  ...               और हमने  एक  बस है वह  एक  भी है    \n",
              "\n",
              "[15 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV1DPC6ej9Ui",
        "colab_type": "text"
      },
      "source": [
        "Okay so now we got some satisfying results. That is it. We are done with translation."
      ]
    }
  ]
}